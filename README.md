# Парсер сайта hh.ru / Web scraper (parser) for hh.ru

Данный парсер считает количество слов, встрчающихся в разделе "Ключевые навыки" для всех вакансий, 
которые будут найдены по указанному ключевому слову и ключевому региону.

### Для чего?
Мне стало интересно, какие ключевые навыки кроме python чаще всего указывают работодатели. 

### Результаты
На 12.08.2017 результаты следующие: при запросе "python" и регионе "Вся Россия":
```python
query = 'python'
area = '113' # вся Россия
```
наиболее часто указываемые ключевые навыки:
* python 493
* linux 248
* git 157
* sql 153
* postgresql 132
* javascript 114
* java 106
* django framework 97
* mysql 93
* c++ 80
* php 66
* bash 63
* ооп 53
* tcp/ip 49
* nginx 46
* тестирование 43
* docker 40

Указаны только те навыки, которые были упомянуты более 40 раз. Всего было проанализировано 2000 вакансий.

### Вывод
Можно сделать вывод, что для тех, кто ищет работу питонистом для большого количества работодателей будет плюсом знание 
***linux, git, sql, postresql, javascript, java, django, mysql***.

# Как он работает

Для работы с парсером необходимо сначала определить запрос и регион (про коды регионов написано ниже) и указать их при
запуске команды парсера:
```ssh
python hh_web_scraper.py --query "python+junior" --area 2
```

Можно использовать и сокращённые ключи параметров:
```ssh
python hh_web_scraper.py -q "python+junior" -a 2
```

Если хотите подключить парсер в своей программе, нужно задать запрос и регион в переменную:
```python
query = 'python+junior'
area = '1'
```


Далее найти все ссылки для вашего запроса и региона:
```python
query = 'python+junior'
area = '1'
links = get_all_offers_links(query, area)
```

Затем распарсить информацию по каждой ссылке:
```python
query = 'python+junior'
area = '1'
links = get_all_offers_links(query, area)

parse_offers(links)
```

В результате в корневом каталоге будут созданы два файла:

**skill_freq.txt** - расположенный по убыванию частоты список всех ключевых навыков, встретившихся по указанному ключевому слову в указанном регионе

**description_freq.txt** - расположенный по убыванию частоты список всех слов, встретившихся по указанному ключевому слову в указанном регионе 



# Коды регионов

Чтобы достать все коды регионов, сделана функция get_and_save_area_codes
которая создает файл с парами Регион - код
далее код региона можно вставлять в вызов функции
для использования просто запустить функцию, и создастся файл, в котором можно посмотреть коды для регионов

Если есть необходимость вытащить коды городов и т.д. из регионов выше, то необоходимо поменять в функции ссылку
вместо `https://hh.ru/search/vacancy`
например `https://hh.ru/search/vacancy?area=1347`.
Тогда в файл запишутся коды всех городов в регионе 1347, т.е. в Республике Башкортостан.

Но в таком случае необходимо доработать функцию `get_and_save_area_codes()` — пропустить первый элемент со ссылкой (т.к. структура первой ссылки немного изменится), например, так:
```python
i = 1
with open('area_codes02.txt', 'w', encoding='utf-8') as f:
    for pair in pairs:
        if i != 1:
            area = pair.find('span', class_='clusters-value__name').get_text()
            code = pair.get('href').split('&')[2].split('=')[1]
            f.write(area+' '+code+'\n')
        i += 1
```
